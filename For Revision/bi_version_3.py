# -*- coding: utf-8 -*-
"""bi version 3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UdSUkKi2guB3zeHnMWyyXHHvi8Kg9GJ1
"""

import pandas as pd
from sklearn.preprocessing import MinMaxScaler
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn.preprocessing import LabelEncoder

df = pd.read_csv('/content/WalmartDataset.csv', encoding='latin-1')
df.head()

summary_statistics = df.describe()
print(summary_statistics)

def print_missing_values(df):
    missing_values = df.isnull().sum()
    print(missing_values)

def visualize_box_plot(df):
  numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns

  # Creating box plots for each numerical column
  for column in numerical_columns:
      plt.figure(figsize=(8, 6))  # Set figure size
      sns.boxplot(x=df[column])  # Create box plot
      plt.xlabel(column)  # Set x-axis label
      plt.title(f'Box Plot of {column}')  # Set plot title
      plt.show()  # Show plot

def normalize_df(date):
  # Initialize the MinMaxScaler
  scaler = MinMaxScaler()

  # Fit and transform the 'Sales' and 'Profit' columns
  df[['Sales', 'Profit']] = scaler.fit_transform(df[['Sales', 'Profit']])

  # Display the first few rows of the dfFrame after normalization
  print(df.head())

def handle_outliers_iqr(df, column):
    Q1 = np.percentile(df[column], 25)
    Q3 = np.percentile(df[column], 75)
    IQR = Q3 - Q1
    lower_fence = Q1 - 1.5 * IQR
    upper_fence = Q3 + 1.5 * IQR


    df.loc[df[column] < lower_fence, column] = lower_fence
    df.loc[df[column] > upper_fence, column] = upper_fence

df.drop(df.columns[0], axis=1, inplace= True)
df.head()

print_missing_values(df)

mode = df['Ship Mode'].mode().iloc[0]
df['Ship Mode'].fillna(mode , inplace= True)

# mean_discount = df['Discount'].mean()
df['Discount'].fillna(0, inplace=True)

print_missing_values(df)

df.drop_duplicates()

# Visualize before handling outliers
visualize_box_plot(df)

for column in df.select_dtypes(include=['number']):
    handle_outliers_iqr(df, column)

#Visulize after handling outliers
visualize_box_plot(df)

print(df.count())

df['Order Date'] = pd.to_datetime(df['Order Date'])
df['Ship Date'] = pd.to_datetime(df['Ship Date'])

# Filter out rows where Ship Date is smaller than Order Date
df = df[df['Ship Date'] >= df['Order Date']]

print(df.count())

# Define the file path for the CSV file
output_file_path = '/content/CleanedWalmartdfset.csv'

# Export the dfFrame to a CSV file
df.to_csv(output_file_path, index=False)

import pandas as pd


df['Order Date'] = pd.to_datetime(df['Order Date'])
df['Ship Date'] = pd.to_datetime(df['Ship Date'])

# Calculate the difference between ship date and order date in days
df['Days_to_Ship'] = (df['Ship Date'] - df['Order Date']).dt.days

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# Select features and target variable
features = df[['Ship Mode', 'Segment', 'Country','Region', 'Category', 'Quantity','Sub-Category','Discount','Profit','Days_to_Ship']]
target = df['Sales']

# Convert categorical variables into dummy/indicator variables
features = pd.get_dummies(features)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)

# Initialize and train the Linear Regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Make predictions on the testing set
y_pred = model.predict(X_test)

from sklearn.metrics import r2_score

# Calculate R^2 score
r2 = r2_score(y_test, y_pred)
print("R^2 Score:", r2)

"""#Decision Tree Regessor

"""

from sklearn.tree import DecisionTreeRegressor

DTR= DecisionTreeRegressor(max_depth=5)

DTR.fit(X_train, y_train)

y_pred=DTR.predict(X_test)

r2_score(y_test,y_pred)

"""#Random Forest Regressor"""

from sklearn.ensemble import RandomForestRegressor

RFR=RandomForestRegressor()

RFR.fit(X_train, y_train)

y_pred=RFR.predict(X_test)

r2_score(y_test,y_pred)

"""time series"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.tsa.stattools import adfuller
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.tsa.arima.model import ARIMA

"""order date as index"""

# Selecting only 'Order Date' and 'Sales' columns
df = df[['Order Date', 'Sales']]

# Displaying the first few rows to verify the result
print(df.head())

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.tsa.stattools import adfuller
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.tsa.arima.model import ARIMA



# Parse dates
df['Order Date'] = pd.to_datetime(df['Order Date'])

# Set 'Month' column as index
df.set_index('Order Date', inplace=True)

df.head()

# Create a time series for sales
sales_time_series = df['Sales']

# step 1

# Downsample the time series to reduce the number of data points
sales_time_series_downsampled = sales_time_series.resample('M').mean().to_frame()
# sales_time_series_downsampled

# # Visualize the downsampled time series
plt.figure(figsize=(10, 6))
# index is the x axis , y is the values of the data frame which is the sales
plt.plot(sales_time_series_downsampled.index,sales_time_series_downsampled['Sales'] , color='blue')
plt.title('Walmart Sales Time Series (Downsampled)')
plt.xlabel('Date')
plt.ylabel('Sales')
plt.grid(True)
plt.show()

"""**step 2: Stationarize the series**"""

# Step 2: Stationarize the series
def stationarize_series(series):
    # Calculate rolling statistics
    rolling_mean = series.rolling(window=12).mean()
    rolling_std = series.rolling(window=12).std()

    # Plot rolling statistics
    plt.figure(figsize=(10, 6))
    plt.plot(series, label='Original', color='blue')
    plt.plot(rolling_mean, label='Rolling Mean', color='red')
    plt.plot(rolling_std, label='Rolling Std', color='green')
    plt.title('Rolling Mean & Standard Deviation')
    plt.xlabel('Date')
    plt.ylabel('Number of Passengers')
    # plt.legend(loc='best')
    plt.grid(True)
    plt.show()

    # Perform Dickey-Fuller test
    result = adfuller(series)
    print('ADF Statistic:', result[0])
    print('p-value:', result[1])
    print('Critical Values:')
    for key, value in result[4].items():
        print('\t{}: {}'.format(key, value))


# Apply stationarize_series function
stationarize_series(sales_time_series_downsampled)

stationarize_series(sales_time_series_downsampled.diff().dropna())

stationarize_series(sales_time_series_downsampled.diff().diff().dropna())

# Finding the value of the d parameter
plt.rcParams.update({'figure.figsize':(9,7), 'figure.dpi':120})

# Original Series
fig, (ax1, ax2, ax3) = plt.subplots(3)
ax1.plot(sales_time_series_downsampled.Sales); ax1.set_title('Original Series'); ax1.axes.xaxis.set_visible(False)
# 1st Differencing
ax2.plot(sales_time_series_downsampled.Sales.diff()); ax2.set_title('1st Order Differencing'); ax2.axes.xaxis.set_visible(False)
# 2nd Differencing
ax3.plot(sales_time_series_downsampled.Sales.diff().diff()); ax3.set_title('2nd Order Differencing')
plt.show()

# Step 3: plot ACF & PACF
from statsmodels.graphics.tsaplots import plot_acf
fig, (ax1, ax2, ax3) = plt.subplots(3)
plot_acf(sales_time_series_downsampled.Sales, ax=ax1)
plot_acf(sales_time_series_downsampled.Sales.diff().dropna(), ax=ax2)
plot_acf(sales_time_series_downsampled.Sales.diff().diff().dropna(), ax=ax3)

# Finding the value of the p parameter

from statsmodels.graphics.tsaplots import plot_pacf
plot_pacf(sales_time_series_downsampled.Sales.diff().dropna())

# Finding the value of the q parameter
plot_acf(sales_time_series_downsampled.Sales.diff().dropna())

pip install pmdarima

from pmdarima import auto_arima
import warnings
warnings.filterwarnings('ignore')

stepwise_fit = auto_arima(sales_time_series_downsampled.Sales, trace=True,suppress_warnings=True)
stepwise_fit.summary()

from statsmodels.tsa.arima_model import ARIMA

"""arima model"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.tsa.stattools import adfuller
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.tsa.arima.model import ARIMA

# Step 4: Build the ARIMA model

model = ARIMA(sales_time_series_downsampled['Sales'], order=(0,1,0))
arima_model = model.fit()


# Step 5: Predict
forecast = arima_model.predict()

# Plot the forecast
plt.figure(figsize=(10, 6))
plt.plot(sales_time_series_downsampled.index,sales_time_series_downsampled['Sales'], label='Original', color='blue')
plt.plot(sales_time_series_downsampled.index ,  forecast, label='Forecast', color='red')
plt.title('Airline Passengers Forecast using ARIMA')
plt.xlabel('Date')
plt.ylabel('Number of Passengers')
plt.legend(loc='best')
plt.grid(True)
plt.show()

sales_time_series_downsampled.head()

sales_time_series_downsampled.tail()

start_index = '2015-1-31'
end_index = '2020-12-1'
forecast = arima_model.predict(start=start_index, end=end_index , dynamic=False)

# Plot the forecast
plt.figure(figsize=(10, 6))
plt.plot(sales_time_series_downsampled.index, sales_time_series_downsampled['Sales'], label='Original', color='blue')
plt.plot(pd.date_range(start=sales_time_series_downsampled.index[-1], periods=len(forecast), freq='MS'), forecast, label='Forecast', color='red')
plt.legend(loc='best')
plt.grid(True)
plt.show()